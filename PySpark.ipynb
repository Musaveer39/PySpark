{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xxT3axM3rC3a",
        "YMZGoGxmt_vJ",
        "Su8v5zUzwnjy",
        "uI93epZiN6UX",
        "TaYaM_mqapRS",
        "WjOsChZ4kJ_q",
        "EwtNKl-Xmd6c",
        "HWiwwgrkABZP",
        "Vxs7mM10FSuy"
      ],
      "authorship_tag": "ABX9TyMUas4FuPeQvoDGlV6LqNjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musaveer39/PySpark/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linux Basics"
      ],
      "metadata": {
        "id": "xxT3axM3rC3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2izjBzysb_uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47f95e8-4a7f-447e-f0d6-f30099a54c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZKYXVy8pl7V",
        "outputId": "bd9ca47e-81e2-417b-bdec-81dba4a83203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRETTY_NAME=\"Ubuntu 22.04.4 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.4 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEed3Wt_qK1g",
        "outputId": "0031cc95-7a61-4033-9f02-292bf5a0da41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux 6405b0515fab 6.1.123+ #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark Basic"
      ],
      "metadata": {
        "id": "YMZGoGxmt_vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "DiQfPCNRuJbt",
        "outputId": "473e8ed1-d8bc-4a23-f5d9-a02c5cc5b43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "BzryJA7xuPSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark =  SparkSession.builder.appName('Basics').getOrCreate()"
      ],
      "metadata": {
        "id": "sEtcIcp3uqgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Hello\",\"World\")]\n",
        "columns = [\"Word1\",\"Word2\"]\n",
        "df = spark.createDataFrame(data,columns)"
      ],
      "metadata": {
        "id": "TiigkhSfu8BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "T6KbhEzOvcBC",
        "outputId": "f7e437fb-2ace-4b6e-f728-2b049adc6547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|Word1|Word2|\n",
            "+-----+-----+\n",
            "|Hello|World|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Transformation and Actions"
      ],
      "metadata": {
        "id": "Su8v5zUzwnjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\", \"IT\", 4500)\n",
        "]\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwBrt3oUwydZ",
        "outputId": "6297f3ee-3279-4e4d-cf68-4861ac82def8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.filter(df.Salary > 3500)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhx_lCd_xdfS",
        "outputId": "1b22bd12-aba3-47d3-ef61-80cc0742cbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| Jane|   Finance|  4000|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grouped and Aggregates\n",
        "df_grouped = df.groupBy(\"Department\").avg(\"Salary\")\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ZdrgWuyMao",
        "outputId": "b4d4ca58-bb16-46d3-ba3f-bddd663eba9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column: Salary with bonus (10%)\n",
        "df_bonus = df.withColumn(\"Salary_With_Bonus\", df.Salary * 1.1)\n",
        "df_bonus.show()"
      ],
      "metadata": {
        "id": "Efaol6iDy5om",
        "outputId": "a6dfa42d-5a0b-4ec9-fb80-40be1c2145b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+------------------+\n",
            "| Name|Department|Salary| Salary_With_Bonus|\n",
            "+-----+----------+------+------------------+\n",
            "| John|     Sales|  3000|3300.0000000000005|\n",
            "| Jane|   Finance|  4000|            4400.0|\n",
            "| Mike|     Sales|  3500|3850.0000000000005|\n",
            "|Alice|   Finance|  3800|            4180.0|\n",
            "|  Bob|        IT|  4500|            4950.0|\n",
            "+-----+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,upper,lower,concat_ws,when,length\n",
        "df.show()"
      ],
      "metadata": {
        "id": "zkb5fpnS0qNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4311f62b-80b2-4fea-f91d-6427e5c8f383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changes case transformations\n",
        "df_upper  = df.withColumn(\"Name_Upper\",upper(col(\"Name\")))\n",
        "df_lower  = df.withColumn(\"Name_Lower\",lower(col(\"Name\")))\n",
        "df_upper.show()\n",
        "df_lower.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZJ2lsJA2jST",
        "outputId": "08bfbc9a-28cc-4ec8-bdc7-3069fd6f36ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_Upper|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      JOHN|\n",
            "| Jane|   Finance|  4000|      JANE|\n",
            "| Mike|     Sales|  3500|      MIKE|\n",
            "|Alice|   Finance|  3800|     ALICE|\n",
            "|  Bob|        IT|  4500|       BOB|\n",
            "+-----+----------+------+----------+\n",
            "\n",
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_Lower|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      john|\n",
            "| Jane|   Finance|  4000|      jane|\n",
            "| Mike|     Sales|  3500|      mike|\n",
            "|Alice|   Finance|  3800|     alice|\n",
            "|  Bob|        IT|  4500|       bob|\n",
            "+-----+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate columns\n",
        "df_concat =df.withColumn(\"Name_Department\",concat_ws(\" - \",\"Name\",\"Department\"))\n",
        "df_concat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzsyI9oB25WF",
        "outputId": "9f5ccde6-5023-43e6-b0f0-a43f0d1084ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+---------------+\n",
            "| Name|Department|Salary|Name_Department|\n",
            "+-----+----------+------+---------------+\n",
            "| John|     Sales|  3000|   John - Sales|\n",
            "| Jane|   Finance|  4000| Jane - Finance|\n",
            "| Mike|     Sales|  3500|   Mike - Sales|\n",
            "|Alice|   Finance|  3800|Alice - Finance|\n",
            "|  Bob|        IT|  4500|       Bob - IT|\n",
            "+-----+----------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lenth = df.withColumn(\"Name_Length\",length(col(\"Name\")))\n",
        "df_lenth.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNTUn2wu3O7m",
        "outputId": "cac6a91d-7c99-430a-c914-1ec8e17dac1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+-----------+\n",
            "| Name|Department|Salary|Name_Length|\n",
            "+-----+----------+------+-----------+\n",
            "| John|     Sales|  3000|          4|\n",
            "| Jane|   Finance|  4000|          4|\n",
            "| Mike|     Sales|  3500|          4|\n",
            "|Alice|   Finance|  3800|          5|\n",
            "|  Bob|        IT|  4500|          3|\n",
            "+-----+----------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional Column (Salary Category)\n",
        "df_conditional = df.withColumn(\"Salary Category\",when(col(\"Salary\") >= 4000,\"High\")\n",
        "                  .when(col(\"Salary\") >= 3500,\"Med\").otherwise(\"Low\"))\n",
        "df_conditional.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxfZ5zwr4SVt",
        "outputId": "6e988ce6-0a0a-4650-bc55-1ea3ca4001be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+---------------+\n",
            "| Name|Department|Salary|Salary Category|\n",
            "+-----+----------+------+---------------+\n",
            "| John|     Sales|  3000|            Low|\n",
            "| Jane|   Finance|  4000|           High|\n",
            "| Mike|     Sales|  3500|            Med|\n",
            "|Alice|   Finance|  3800|            Med|\n",
            "|  Bob|        IT|  4500|           High|\n",
            "+-----+----------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed = df_conditional.withColumnRenamed(\"Salary\",\"Base Salary\")\n",
        "df_renamed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uchOuhf5AjS",
        "outputId": "0fcff811-f161-4ac1-8322-210fe44de934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----------+---------------+\n",
            "| Name|Department|Base Salary|Salary Category|\n",
            "+-----+----------+-----------+---------------+\n",
            "| John|     Sales|       3000|            Low|\n",
            "| Jane|   Finance|       4000|           High|\n",
            "| Mike|     Sales|       3500|            Med|\n",
            "|Alice|   Finance|       3800|            Med|\n",
            "|  Bob|        IT|       4500|           High|\n",
            "+-----+----------+-----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4I3Eyhf6WWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Transformations"
      ],
      "metadata": {
        "id": "uI93epZiN6UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
        "columns = [\"Name\",\"Department\",\"Salary\"]\n",
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\", \"IT\", 4500)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "ihrRYzU2OIE-",
        "outputId": "aedfe9ce-09eb-41aa-9c43-83ef35bb6204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count by Department\n",
        "df_count =  df.groupBy(\"Department\").count()\n",
        "df_count.show()"
      ],
      "metadata": {
        "id": "Al23S6P2Oy-4",
        "outputId": "63cf254d-00c6-44d8-997e-fe0e0f95626e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|     Sales|    2|\n",
            "|   Finance|    2|\n",
            "|        IT|    1|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Department and calculate average salary\n",
        "df.groupBy(\"Department\").avg(\"Salary\").show()"
      ],
      "metadata": {
        "id": "8nqqldByO9Vc",
        "outputId": "c5138231-c902-4265-c4d6-044e0c3e55c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Department and calculate multiple aggregations\n",
        "df.groupBy(\"Department\").agg({\"Salary\": \"sum\", \"Salary\": \"max\",\"Salary\":'min'}).show()"
      ],
      "metadata": {
        "id": "K9zrSgbqPNdT",
        "outputId": "77b38505-8c8e-4b8b-ebcf-1d652b4f6df8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|min(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|       3000|\n",
            "|   Finance|       3800|\n",
            "|        IT|       4500|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "df.groupBy('Department').agg(f.avg('Salary'),f.max('Salary'),f.min('Salary')).show()"
      ],
      "metadata": {
        "id": "Y-8AhY-6Pyx5",
        "outputId": "cdcbfb36-c220-45e2-b667-75f216c96734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+-----------+\n",
            "|Department|avg(Salary)|max(Salary)|min(Salary)|\n",
            "+----------+-----------+-----------+-----------+\n",
            "|     Sales|     3250.0|       3500|       3000|\n",
            "|   Finance|     3900.0|       4000|       3800|\n",
            "|        IT|     4500.0|       4500|       4500|\n",
            "+----------+-----------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another DataFrame for department info\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\")\n",
        "]\n",
        "dept_columns = [\"Department\", \"Location\"]\n"
      ],
      "metadata": {
        "id": "VRwJvXRTQUDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_df = spark.createDataFrame(dept_data, dept_columns)\n",
        "joined_df = df.join(dept_df, on='Department', how='inner')\n",
        "joined_df.show()"
      ],
      "metadata": {
        "id": "-RiWOHWESWh8",
        "outputId": "1c7354a2-0ef6-4150-8944-7c9ae99c0d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+------+----------+\n",
            "|Department| Name|Salary|  Location|\n",
            "+----------+-----+------+----------+\n",
            "|   Finance| Jane|  4000|Building B|\n",
            "|   Finance|Alice|  3800|Building B|\n",
            "|        IT|  Bob|  4500|Building C|\n",
            "|     Sales| John|  3000|Building A|\n",
            "|     Sales| Mike|  3500|Building A|\n",
            "+----------+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left join\n",
        "left_joined_df = df.join(dept_df, on='Department', how='left')\n",
        "left_joined_df.show()"
      ],
      "metadata": {
        "id": "HTot-BsUS2mB",
        "outputId": "d164ac2a-9af2-450c-c523-e0c54b2424d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+------+----------+\n",
            "|Department| Name|Salary|  Location|\n",
            "+----------+-----+------+----------+\n",
            "|     Sales| John|  3000|Building A|\n",
            "|   Finance| Jane|  4000|Building B|\n",
            "|     Sales| Mike|  3500|Building A|\n",
            "|   Finance|Alice|  3800|Building B|\n",
            "|        IT|  Bob|  4500|Building C|\n",
            "+----------+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Employee DataFrame\n",
        "emp_data = [\n",
        "    (1, \"John\", \"Sales\", 3000),\n",
        "    (2, \"Jane\", \"Finance\", 4000),\n",
        "    (3, \"Mike\", \"Sales\", 3500),\n",
        "    (4, \"Alice\", \"HR\", 3800),\n",
        "    (5, \"Bob\", \"IT\", 4500),\n",
        "    (6, \"Sam\", \"Support\", 3200)\n",
        "]\n",
        "emp_cols = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "emp_df = spark.createDataFrame(emp_data, emp_cols)\n",
        "\n",
        "# Department DataFrame\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\"),\n",
        "    (\"Admin\", \"Building D\")\n",
        "]\n",
        "dept_cols = [\"Department\", \"Location\"]\n",
        "dept_df = spark.createDataFrame(dept_data, dept_cols)\n",
        "\n",
        "# Display both\n",
        "emp_df.show()\n",
        "dept_df.show()"
      ],
      "metadata": {
        "id": "A1sKDar7VYSH",
        "outputId": "ff700801-a5d5-4f2c-8f92-708f93397665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1| John|     Sales|  3000|\n",
            "|    2| Jane|   Finance|  4000|\n",
            "|    3| Mike|     Sales|  3500|\n",
            "|    4|Alice|        HR|  3800|\n",
            "|    5|  Bob|        IT|  4500|\n",
            "|    6|  Sam|   Support|  3200|\n",
            "+-----+-----+----------+------+\n",
            "\n",
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "|     Admin|Building D|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Full outer join\n",
        "full_df = emp_df.join(dept_df, on='Department', how='full')\n",
        "full_df.show()"
      ],
      "metadata": {
        "id": "ChktBUK9Vvdn",
        "outputId": "ed2b5588-3107-4d0d-a5d7-34ea1196ba5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+------+----------+\n",
            "|Department|EmpID| Name|Salary|  Location|\n",
            "+----------+-----+-----+------+----------+\n",
            "|     Admin| NULL| NULL|  NULL|Building D|\n",
            "|   Finance|    2| Jane|  4000|Building B|\n",
            "|        HR|    4|Alice|  3800|      NULL|\n",
            "|        IT|    5|  Bob|  4500|Building C|\n",
            "|     Sales|    1| John|  3000|Building A|\n",
            "|     Sales|    3| Mike|  3500|Building A|\n",
            "|   Support|    6|  Sam|  3200|      NULL|\n",
            "+----------+-----+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced DataFrame Operations"
      ],
      "metadata": {
        "id": "maiLfVuvY213"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Window Functions"
      ],
      "metadata": {
        "id": "TaYaM_mqapRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Window Functions\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", 2000, [\"math\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (2, \"Bob\", 1500, [\"english\"], {\"city\": \"SF\", \"zip\": \"94105\"}),\n",
        "    (3, \"Charlie\", 2200, [\"math\", \"history\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (4, \"David\", 1200, [\"art\"], {\"city\": \"LA\", \"zip\": \"90001\"}),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=[\"id\", \"name\", \"salary\", \"subjects\", \"address\"])\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "id": "-w6uEMzXWmCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf5ffbd-575e-43c9-bf7c-d09255b2c73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+------------------------+---------------------------+\n",
            "|id |name   |salary|subjects                |address                    |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "|1  |Alice  |2000  |[math, science]         |{zip -> 10001, city -> NYC}|\n",
            "|2  |Bob    |1500  |[english]               |{zip -> 94105, city -> SF} |\n",
            "|3  |Charlie|2200  |[math, history, science]|{zip -> 10001, city -> NYC}|\n",
            "|4  |David  |1200  |[art]                   |{zip -> 90001, city -> LA} |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "window_spec = Window.partitionBy(\"address.city\").orderBy(\"salary\")\n",
        "df.withColumn('rank' ,rank().over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvFxvMWWbeLB",
        "outputId": "6739052e-4078-42aa-f168-d43231b2ca6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------------------+--------------------+----+\n",
            "| id|   name|salary|            subjects|             address|rank|\n",
            "+---+-------+------+--------------------+--------------------+----+\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|   1|\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|   1|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|   2|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|   1|\n",
            "+---+-------+------+--------------------+--------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, row_number, rank, dense_rank, max, sum, avg\n",
        "\n",
        "# Employee Data\n",
        "data = [\n",
        "    (1, \"John\", \"Sales\", 3000),\n",
        "    (2, \"Jane\", \"Finance\", 4000),\n",
        "    (3, \"Mike\", \"Sales\", 3500),\n",
        "    (4, \"Alice\", \"Finance\", 3800),\n",
        "    (5, \"Bob\", \"IT\", 4500),\n",
        "    (6, \"Tom\", \"Sales\", 3700),\n",
        "    (7, \"Jerry\", \"Finance\", 4200),\n",
        "    (8, \"Sam\", \"IT\", 4700),\n",
        "    (9, \"Steve\", \"Sales\", 3100),\n",
        "    (10, \"Rachel\", \"IT\", 4600)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrKjPkpZc8VS",
        "outputId": "ab6564a7-a213-44ee-8efc-cc0f0322201c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+------+\n",
            "|EmpID|  Name|Department|Salary|\n",
            "+-----+------+----------+------+\n",
            "|    1|  John|     Sales|  3000|\n",
            "|    2|  Jane|   Finance|  4000|\n",
            "|    3|  Mike|     Sales|  3500|\n",
            "|    4| Alice|   Finance|  3800|\n",
            "|    5|   Bob|        IT|  4500|\n",
            "|    6|   Tom|     Sales|  3700|\n",
            "|    7| Jerry|   Finance|  4200|\n",
            "|    8|   Sam|        IT|  4700|\n",
            "|    9| Steve|     Sales|  3100|\n",
            "|   10|Rachel|        IT|  4600|\n",
            "+-----+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec = Window.partitionBy(\"Department\").orderBy(col('Salary').desc())\n",
        "df.withColumn(\"Rank\",rank().over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXU4bouFdQQ0",
        "outputId": "7445e058-bb7e-463e-c352-cb89faeb28f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+------+----+\n",
            "|EmpID|  Name|Department|Salary|Rank|\n",
            "+-----+------+----------+------+----+\n",
            "|    7| Jerry|   Finance|  4200|   1|\n",
            "|    2|  Jane|   Finance|  4000|   2|\n",
            "|    4| Alice|   Finance|  3800|   3|\n",
            "|    8|   Sam|        IT|  4700|   1|\n",
            "|   10|Rachel|        IT|  4600|   2|\n",
            "|    5|   Bob|        IT|  4500|   3|\n",
            "|    6|   Tom|     Sales|  3700|   1|\n",
            "|    3|  Mike|     Sales|  3500|   2|\n",
            "|    9| Steve|     Sales|  3100|   3|\n",
            "|    1|  John|     Sales|  3000|   4|\n",
            "+-----+------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec =  Window.partitionBy('Department')\n",
        "df.withColumn('Max Salary',max('Salary').over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSPAlUIZdbJA",
        "outputId": "47617411-9fed-4e38-e5e5-7537cd5987c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+------+----------+\n",
            "|EmpID|  Name|Department|Salary|Max Salary|\n",
            "+-----+------+----------+------+----------+\n",
            "|    2|  Jane|   Finance|  4000|      4200|\n",
            "|    4| Alice|   Finance|  3800|      4200|\n",
            "|    7| Jerry|   Finance|  4200|      4200|\n",
            "|    5|   Bob|        IT|  4500|      4700|\n",
            "|    8|   Sam|        IT|  4700|      4700|\n",
            "|   10|Rachel|        IT|  4600|      4700|\n",
            "|    1|  John|     Sales|  3000|      3700|\n",
            "|    3|  Mike|     Sales|  3500|      3700|\n",
            "|    6|   Tom|     Sales|  3700|      3700|\n",
            "|    9| Steve|     Sales|  3100|      3700|\n",
            "+-----+------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('Department').max('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3avf_8qBenwr",
        "outputId": "48f66403-79d1-4b54-c0d3-0a1cfed1637e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|max(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|       3700|\n",
            "|   Finance|       4200|\n",
            "|        IT|       4700|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec = Window.partitionBy('Department').orderBy('Salary').rowsBetween(Window.unboundedPreceding,0)\n",
        "df.withColumn('Cummulative Salary' ,sum('Salary').over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyhS__OjfGlR",
        "outputId": "a43fe04a-865a-4878-b587-f8756b597158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+------+------------------+\n",
            "|EmpID|  Name|Department|Salary|Cummulative Salary|\n",
            "+-----+------+----------+------+------------------+\n",
            "|    4| Alice|   Finance|  3800|              3800|\n",
            "|    2|  Jane|   Finance|  4000|              7800|\n",
            "|    7| Jerry|   Finance|  4200|             12000|\n",
            "|    5|   Bob|        IT|  4500|              4500|\n",
            "|   10|Rachel|        IT|  4600|              9100|\n",
            "|    8|   Sam|        IT|  4700|             13800|\n",
            "|    1|  John|     Sales|  3000|              3000|\n",
            "|    9| Steve|     Sales|  3100|              6100|\n",
            "|    3|  Mike|     Sales|  3500|              9600|\n",
            "|    6|   Tom|     Sales|  3700|             13300|\n",
            "+-----+------+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", 2000, [\"math\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (2, \"Bob\", 1500, [\"english\"], {\"city\": \"SF\", \"zip\": \"94105\"}),\n",
        "    (3, \"Charlie\", 2200, [\"math\", \"history\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (4, \"David\", 1200, [\"art\"], {\"city\": \"LA\", \"zip\": \"90001\"}),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=[\"id\", \"name\", \"salary\", \"subjects\", \"address\"])\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L5zwubI-96t",
        "outputId": "cf05b982-407c-4043-a350-fcbd6e2903bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+------------------------+---------------------------+\n",
            "|id |name   |salary|subjects                |address                    |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "|1  |Alice  |2000  |[math, science]         |{zip -> 10001, city -> NYC}|\n",
            "|2  |Bob    |1500  |[english]               |{zip -> 94105, city -> SF} |\n",
            "|3  |Charlie|2200  |[math, history, science]|{zip -> 10001, city -> NYC}|\n",
            "|4  |David  |1200  |[art]                   |{zip -> 90001, city -> LA} |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(IntegerType())\n",
        "def subject_count(subjects):\n",
        "    return len(subjects)\n",
        "\n",
        "df.withColumn('Subject Count',subject_count(df.subjects)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5IG10kl5aJE",
        "outputId": "7dba5f71-2c34-46f4-8337-1f04f6b50cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "| id|   name|salary|            subjects|             address|Subject Count|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|            2|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|            1|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|            3|\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|            1|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "@pandas_udf(DoubleType())\n",
        "def multiply_by_two(s: pd.Series) -> pd.Series:\n",
        "    return s * 2\n",
        "df.withColumn('Double_Salary',multiply_by_two(df.salary)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJh8dack-5L-",
        "outputId": "0f87ea6f-07e3-4977-c22e-9a31885c65fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "| id|   name|salary|            subjects|             address|Double_Salary|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|       4000.0|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|       3000.0|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|       4400.0|\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|       2400.0|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Use Case Activities\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import col, rank, avg, udf, pandas_udf\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "\n",
        "employees_data = [\n",
        "    (1, \"Alice\", \"HR\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"IT\", 4500),\n",
        "    (5, \"Eve\", \"Finance\", 5000),\n",
        "    (6, \"Frank\", \"Finance\", 4800),\n",
        "]\n",
        "\n",
        "employees_df = spark.createDataFrame(employees_data, [\"id\", \"name\", \"department\", \"salary\"])\n",
        "employees_df.show()\n",
        "\n",
        "departments_data = [\n",
        "    (\"HR\", \"New York\"),\n",
        "    (\"IT\", \"San Francisco\"),\n",
        "    (\"Finance\", \"Chicago\"),\n",
        "]\n",
        "\n",
        "departments_df = spark.createDataFrame(departments_data, [\"department\", \"location\"])\n",
        "departments_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p0vMFOq_m2K",
        "outputId": "9dd8b809-a25c-4488-e415-af4ddff7fffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| id| name|department|salary|\n",
            "+---+-----+----------+------+\n",
            "|  1|Alice|        HR|  3000|\n",
            "|  2|  Bob|        IT|  4000|\n",
            "|  3|Cathy|        HR|  3500|\n",
            "|  4|David|        IT|  4500|\n",
            "|  5|  Eve|   Finance|  5000|\n",
            "|  6|Frank|   Finance|  4800|\n",
            "+---+-----+----------+------+\n",
            "\n",
            "+----------+-------------+\n",
            "|department|     location|\n",
            "+----------+-------------+\n",
            "|        HR|     New York|\n",
            "|        IT|San Francisco|\n",
            "|   Finance|      Chicago|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "employees_df.withColumn(\"rank\", rank().over(window_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJl_iXvBCOXU",
        "outputId": "fe0f75ca-4a02-43ea-ae2a-beaf5f609ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+----+\n",
            "| id| name|department|salary|rank|\n",
            "+---+-----+----------+------+----+\n",
            "|  6|Frank|   Finance|  4800|   1|\n",
            "|  5|  Eve|   Finance|  5000|   2|\n",
            "|  1|Alice|        HR|  3000|   1|\n",
            "|  3|Cathy|        HR|  3500|   2|\n",
            "|  2|  Bob|        IT|  4000|   1|\n",
            "|  4|David|        IT|  4500|   2|\n",
            "+---+-----+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec = Window.partitionBy('department')\n",
        "employees_df.withColumn('Average salary', avg('salary').over(window_spec)).show()\n",
        "\n",
        "employees_df.groupBy('department').avg('salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xV746k5CeyV",
        "outputId": "0cfbfa39-2851-4c5d-84e8-0cb955b55a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+--------------+\n",
            "| id| name|department|salary|Average salary|\n",
            "+---+-----+----------+------+--------------+\n",
            "|  5|  Eve|   Finance|  5000|        4900.0|\n",
            "|  6|Frank|   Finance|  4800|        4900.0|\n",
            "|  1|Alice|        HR|  3000|        3250.0|\n",
            "|  3|Cathy|        HR|  3500|        3250.0|\n",
            "|  2|  Bob|        IT|  4000|        4250.0|\n",
            "|  4|David|        IT|  4500|        4250.0|\n",
            "+---+-----+----------+------+--------------+\n",
            "\n",
            "+----------+-----------+\n",
            "|department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|     3250.0|\n",
            "|        IT|     4250.0|\n",
            "|   Finance|     4900.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Ops"
      ],
      "metadata": {
        "id": "WjOsChZ4kJ_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"John\", [\"Python\", \"Java\"]),\n",
        "    (\"Jane\", [\"SQL\", \"R\", \"Scala\"]),\n",
        "    (\"Mike\", [])\n",
        "]\n",
        "columns = [\"Name\", \"Skills\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFCzJj7GDxhi",
        "outputId": "a6a29a35-6cd7-4dbc-adfc-a058ae79cf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------+\n",
            "|Name|Skills         |\n",
            "+----+---------------+\n",
            "|John|[Python, Java] |\n",
            "|Jane|[SQL, R, Scala]|\n",
            "|Mike|[]             |\n",
            "+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_exploded = df.withColumn('Skill' , explode('Skills'))\n",
        "df_exploded.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TEucMrrkcRG",
        "outputId": "9779ee00-bc59-4ad9-e5ba-f421ef07d4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------+------+\n",
            "|Name|         Skills| Skill|\n",
            "+----+---------------+------+\n",
            "|John| [Python, Java]|Python|\n",
            "|John| [Python, Java]|  Java|\n",
            "|Jane|[SQL, R, Scala]|   SQL|\n",
            "|Jane|[SQL, R, Scala]|     R|\n",
            "|Jane|[SQL, R, Scala]| Scala|\n",
            "+----+---------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('people')\n",
        "df_lateral = spark.sql(\"SELECT Name,Skill FROM people lateral view explode(Skills) as Skill\")\n",
        "df_lateral.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ihchwqkiqQ",
        "outputId": "927dedaf-e8f0-4c15-91c3-17f690afb0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Name| Skill|\n",
            "+----+------+\n",
            "|John|Python|\n",
            "|John|  Java|\n",
            "|Jane|   SQL|\n",
            "|Jane|     R|\n",
            "|Jane| Scala|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"ProductA\", \"Jan\", 100),\n",
        "    (\"ProductA\", \"Feb\", 150),\n",
        "    (\"ProductA\", \"Mar\", 120),\n",
        "    (\"ProductB\", \"Jan\", 200),\n",
        "    (\"ProductB\", \"Feb\", 230),\n",
        "    (\"ProductB\", \"Mar\", 210),\n",
        "]\n",
        "columns = [\"Product\", \"Month\", \"Sales\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUsw-KwOmHr9",
        "outputId": "ef8770f6-5ba7-4343-9d14-b80da0a58f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Feb|  150|\n",
            "|ProductA|  Mar|  120|\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductB|  Mar|  210|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = df.groupBy(\"Product\").pivot(\"Month\").sum(\"Sales\")\n",
        "pivot_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3TtNjoQylVf",
        "outputId": "526bd8e4-31d1-4cfd-a9e4-67cad0e737b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+---+\n",
            "| Product|Feb|Jan|Mar|\n",
            "+--------+---+---+---+\n",
            "|ProductB|230|200|210|\n",
            "|ProductA|150|100|120|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unpivot_df = pivot_df.selectExpr(\n",
        "    \"Product\",\n",
        "    \"stack(3,'Jan',Jan,'Mar',Mar,'Feb',Feb) as (Month,Sales)\"\n",
        ")\n",
        "unpivot_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koYbnVqZy5fo",
        "outputId": "69318cb1-1ead-4aab-9f27-cba100819911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Mar|  210|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Mar|  120|\n",
            "|ProductA|  Feb|  150|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BwA5SZ30VHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RDD Resilient Distributed Dataset"
      ],
      "metadata": {
        "id": "EwtNKl-Xmd6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().setAppName('MySparkApp').setMaster('local[*]')\n",
        "sc = SparkContext(conf = conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "cpcNkA8kqv-Y",
        "outputId": "fa38f3b3-06a7-4440-b774-f8b6e8adb366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=MySparkApp, master=local[*]) created by __init__ at /tmp/ipython-input-4-1978198528.py:1 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-4012566762.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MySparkApp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=MySparkApp, master=local[*]) created by __init__ at /tmp/ipython-input-4-1978198528.py:1 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "# Transformation: Map\n",
        "rdd_mapped = rdd.map(lambda x:x*2)\n",
        "\n",
        "print(rdd_mapped.collect()) #output: 2,4,6,8,10\n",
        "\n",
        "rdd_filtered = rdd.filter(lambda x:x%2 == 0)\n",
        "print(rdd_filtered.collect())\n",
        "\n",
        "#rdd_reduce = rdd.reduce(lambda x,y:x+y)\n",
        "#print(rdd_reduce.collect())\n",
        "\n",
        "rdd = sc.parallelize([1,2,3])\n",
        "\n",
        "rdd_flat = rdd.flatMap(lambda x: range(x,x+3))\n",
        "\n",
        "#collect the result\n",
        "print(rdd_flat.collect())\n",
        "\n",
        "rdd = sc.parallelize(['Hello','world'])\n",
        "\n",
        "rdd_flat = rdd.flatMap(lambda x: list(x))\n",
        "\n",
        "print(rdd_flat.collect())\n",
        "\n",
        "rdd = sc.parallelize([[1,2],[3,4],[5]])\n",
        "\n",
        "rdd_flat = rdd.flatMap(lambda x:x)\n",
        "\n",
        "print(rdd_flat.collect())\n",
        "\n",
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "rdd_group = rdd.groupBy(lambda x: 'even' if x % 2 == 0 else 'odd')\n",
        "\n",
        "print([(key, list(value)) for key, value in rdd_group.collect()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYJcjMKbmlSK",
        "outputId": "88c7028e-aaf7-43c6-8771-bd2dffcab53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n",
            "[2, 4]\n",
            "[1, 2, 3, 2, 3, 4, 3, 4, 5]\n",
            "['H', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd']\n",
            "[1, 2, 3, 4, 5]\n",
            "[('even', [2, 4]), ('odd', [1, 3, 5])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"John\", \"HR\", 5000),\n",
        "    (2, \"Jane\", \"IT\", 8000),\n",
        "    (3, \"Mike\", \"IT\", 6000),\n",
        "    (4, \"Sara\", \"Finance\", 7000),\n",
        "    (5, \"David\", \"HR\", 5500)\n",
        "]\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameOperations\").getOrCreate()\n",
        "\n",
        "# Define column names\n",
        "columns = [\"ID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "# Create a DataFrame from the sample data\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oFvT73ioUYj",
        "outputId": "3c6330ff-e148-45a3-f9d0-572a1a9183b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| ID| Name|Department|Salary|\n",
            "+---+-----+----------+------+\n",
            "|  1| John|        HR|  5000|\n",
            "|  2| Jane|        IT|  8000|\n",
            "|  3| Mike|        IT|  6000|\n",
            "|  4| Sara|   Finance|  7000|\n",
            "|  5|David|        HR|  5500|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('Name','Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nQrtZKL8ssJ",
        "outputId": "e3877f72-2a78-405f-9cdd-a5ae93dbcb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "| Name|Salary|\n",
            "+-----+------+\n",
            "| John|  5000|\n",
            "| Jane|  8000|\n",
            "| Mike|  6000|\n",
            "| Sara|  7000|\n",
            "|David|  5500|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df['Salary']>=6000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DOV6fku8914",
        "outputId": "74df2e60-4afe-4e16-e2bb-53e7a1cbff82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------+------+\n",
            "| ID|Name|Department|Salary|\n",
            "+---+----+----------+------+\n",
            "|  2|Jane|        IT|  8000|\n",
            "|  3|Mike|        IT|  6000|\n",
            "|  4|Sara|   Finance|  7000|\n",
            "+---+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Bonus' , df['Salary']*0.1)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXBlUg2Z9IEW",
        "outputId": "39e4a27b-9530-4a88-ba94-a27c5da232ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+-----+\n",
            "| ID| Name|Department|Salary|Bonus|\n",
            "+---+-----+----------+------+-----+\n",
            "|  1| John|        HR|  5000|500.0|\n",
            "|  2| Jane|        IT|  8000|800.0|\n",
            "|  3| Mike|        IT|  6000|600.0|\n",
            "|  4| Sara|   Finance|  7000|700.0|\n",
            "|  5|David|        HR|  5500|550.0|\n",
            "+---+-----+----------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Bonus')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3-X21gu9fQV",
        "outputId": "6e405eba-7ce8-4433-eb99-bc71b9495a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| ID| Name|Department|Salary|\n",
            "+---+-----+----------+------+\n",
            "|  1| John|        HR|  5000|\n",
            "|  2| Jane|        IT|  8000|\n",
            "|  3| Mike|        IT|  6000|\n",
            "|  4| Sara|   Finance|  7000|\n",
            "|  5|David|        HR|  5500|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "df.groupBy(\"Department\").agg(avg(\"Salary\").alias('Avg-Salary')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhUC0Jdf96iZ",
        "outputId": "6cf09d15-66c5-476b-93a4-018799f5d0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Department|Avg-Salary|\n",
            "+----------+----------+\n",
            "|        HR|    5250.0|\n",
            "|        IT|    7000.0|\n",
            "|   Finance|    7000.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHo3oI5e-WeS",
        "outputId": "2cd3b8b7-4542-4f86-bfa5-3140670eecfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|        HR|    2|\n",
            "|        IT|    2|\n",
            "|   Finance|    1|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumnRenamed('Salary','Salary_After_Tax').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxGr80hg-jkh",
        "outputId": "57aaf7dd-596e-4205-98ed-eba18a7b216b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+----------------+\n",
            "| ID| Name|Department|Salary_After_Tax|\n",
            "+---+-----+----------+----------------+\n",
            "|  1| John|        HR|            5000|\n",
            "|  2| Jane|        IT|            8000|\n",
            "|  3| Mike|        IT|            6000|\n",
            "|  4| Sara|   Finance|            7000|\n",
            "|  5|David|        HR|            5500|\n",
            "+---+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(df['Salary'].desc()).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWL1cOaP_jQL",
        "outputId": "1b746ed7-b280-415a-81e9-5c2dbd94cae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------+------+\n",
            "| ID|Name|Department|Salary|\n",
            "+---+----+----------+------+\n",
            "|  2|Jane|        IT|  8000|\n",
            "|  4|Sara|   Finance|  7000|\n",
            "|  3|Mike|        IT|  6000|\n",
            "+---+----+----------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = df.collect()\n",
        "for row in data_list:\n",
        "  print(row.Name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4i0rfV1-y7I",
        "outputId": "c25a5260-056c-47fb-db4c-0c9f32dd22c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John\n",
            "Jane\n",
            "Mike\n",
            "Sara\n",
            "David\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "HWiwwgrkABZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Initialize SparkConf and SparkContext\n",
        "# conf = SparkConf().setAppName(\"MySparkApp\").setMaster(\"local[*]\")\n",
        "# sc = SparkContext(conf=conf)\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameOperations\").getOrCreate()\n",
        "\n",
        "#sc = spark.SparkContext\n",
        "\n",
        "rdd = sc.parallelize([Row(name=\"Alice\", age=25), Row(name=\"Bob\", age=30)])\n",
        "dataset = spark.createDataFrame(rdd)\n",
        "dataset.filter(dataset.age > 25)\n",
        "dataset.select(\"name\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbDF79VW_YjH",
        "outputId": "8f258030-6ccb-492c-8648-ccb1b75929ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "|Alice|\n",
            "|  Bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSQLBasics\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"Sales\", 4500),\n",
        "    (5, \"Eva\", \"IT\", 4200)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeV2MOgHBDmv",
        "outputId": "1179e1e4-fa71-4c30-af14-ef86ab147a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    4|David|     Sales|  4500|\n",
            "|    5|  Eva|        IT|  4200|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = df.rdd\n",
        "print(\"RDD Example:\", rdd.map(lambda x: (x.Name,x.Salary)).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdHdzeoJC82i",
        "outputId": "c4f5538c-e9f2-493e-a292-de75d368f9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD Example: [('Alice', 3000), ('Bob', 4000), ('Cathy', 3500), ('David', 4500), ('Eva', 4200)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON ans CSV"
      ],
      "metadata": {
        "id": "Vxs7mM10FSuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnJ6u8lUDoIT",
        "outputId": "37381904-d2b7-4966-8fe2-0983a90a091b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode(\"overwrite\").json(\"/content/json_data\")"
      ],
      "metadata": {
        "id": "XJ1kWJuLFOt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/json_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejdMG-mLFsbC",
        "outputId": "cf1ae8c5-365d-45c5-b1ad-080ee770539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-765914e2-8fdc-4ee5-bab7-ba226c522d88-c000.json  _SUCCESS\n",
            "part-00001-765914e2-8fdc-4ee5-bab7-ba226c522d88-c000.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/json_data/part-00000-765914e2-8fdc-4ee5-bab7-ba226c522d88-c000.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e_v5nMPF3Jm",
        "outputId": "ab62f76d-81d9-44b5-cfa5-e67702ea2cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"EmpID\":1,\"Name\":\"Alice\",\"Department\":\"Sales\",\"Salary\":3000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strPath = \"/content/csv_data\"\n",
        "df.write.mode('overwrite').option('header','true').csv(strPath)"
      ],
      "metadata": {
        "id": "qE8w55ZRF8sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/csv_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-w5gIe3HQUA",
        "outputId": "325f590f-c2ab-4ca9-aa13-6c7717bb3747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-ddae1ff3-98bd-43ec-8f7a-2bc8f2c36455-c000.csv  _SUCCESS\n",
            "part-00001-ddae1ff3-98bd-43ec-8f7a-2bc8f2c36455-c000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/csv_data/part-00000-ddae1ff3-98bd-43ec-8f7a-2bc8f2c36455-c000.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lrBz7z6HjOx",
        "outputId": "8de67d9d-9dd3-4b4c-ffad-ee5d8a060e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmpID,Name,Department,Salary\n",
            "1,Alice,Sales,3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNP4BdnKHw1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Streaming"
      ],
      "metadata": {
        "id": "ZiUVZez5odCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "# Generate 30 records with random data\n",
        "names = [\"John\", \"Jane\", \"Mike\", \"Sara\", \"David\", \"Emily\", \"George\", \"Nina\", \"Tom\", \"Anna\"]\n",
        "departments = [\"Sales\", \"IT\", \"HR\", \"Finance\", \"Marketing\"]\n",
        "salaries = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "# Create and open a CSV file for writing\n",
        "with open('employee_data.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writerow([\"ID\", \"Name\", \"Department\", \"Salary\"])\n",
        "\n",
        "    # Write the 30 records\n",
        "    for i in range(1, 31):\n",
        "        name = random.choice(names)\n",
        "        department = random.choice(departments)\n",
        "        salary = random.choice(salaries)\n",
        "        writer.writerow([i, name, department, salary])\n",
        "\n",
        "print(\"CSV file 'employee_data.csv' has been generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZopuwkKoo0P",
        "outputId": "51f2c1f4-9815-49c4-b1ec-5fe144a1701b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'employee_data.csv' has been generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat /content/employee_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o16LdlP-o7UQ",
        "outputId": "b8749896-d349-4f84-bf3c-7611c73f1079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID,Name,Department,Salary\r\n",
            "1,George,Finance,8000\r\n",
            "2,Tom,IT,10000\r\n",
            "3,Nina,HR,6000\r\n",
            "4,Jane,Marketing,9000\r\n",
            "5,Nina,Sales,10000\r\n",
            "6,Mike,Marketing,7000\r\n",
            "7,Anna,IT,7000\r\n",
            "8,John,HR,6000\r\n",
            "9,Tom,Marketing,4000\r\n",
            "10,Emily,IT,6000\r\n",
            "11,Mike,Sales,5000\r\n",
            "12,David,IT,7000\r\n",
            "13,Mike,IT,6000\r\n",
            "14,George,Marketing,4000\r\n",
            "15,Nina,Sales,10000\r\n",
            "16,John,Marketing,6000\r\n",
            "17,Anna,Sales,4000\r\n",
            "18,George,Sales,6000\r\n",
            "19,Anna,Marketing,4000\r\n",
            "20,Sara,Finance,10000\r\n",
            "21,John,Marketing,3000\r\n",
            "22,Jane,HR,5000\r\n",
            "23,Nina,Marketing,10000\r\n",
            "24,John,Sales,4000\r\n",
            "25,Emily,IT,4000\r\n",
            "26,Nina,Sales,3000\r\n",
            "27,Sara,HR,6000\r\n",
            "28,Tom,HR,8000\r\n",
            "29,Anna,IT,9000\r\n",
            "30,Sara,IT,4000\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/emp_data"
      ],
      "metadata": {
        "id": "uuWY0UW-pGk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/employee_data.csv /content/emp_data/"
      ],
      "metadata": {
        "id": "lUwcp3YJpcWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, IntegerType, StringType\n",
        "\n",
        "schema = StructType() \\\n",
        "  .add(\"EmpID\", IntegerType()) \\\n",
        "  .add(\"Name\", StringType()) \\\n",
        "  .add(\"Department\", StringType()) \\\n",
        "  .add(\"Salary\", IntegerType())\n",
        "\n",
        "print(schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOpkZ4jJpyNZ",
        "outputId": "4665faa5-0409-4bd2-f88a-fa1ef90b6bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructType([StructField('EmpID', IntegerType(), True), StructField('Name', StringType(), True), StructField('Department', StringType(), True), StructField('Salary', IntegerType(), True)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream_df = spark.readStream \\\n",
        "  .option(\"sep\", \",\") \\\n",
        "  .schema(schema) \\\n",
        "  .csv(\"/content/emp_data/\")"
      ],
      "metadata": {
        "id": "KhWMVOpmrekv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper\n",
        "transformed_df = stream_df.withColumn(\"NameUPPER\",upper(\"Name\"))"
      ],
      "metadata": {
        "id": "pn8O6QRJsdF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = transformed_df.writeStream \\\n",
        "  .outputMode(\"append\") \\\n",
        "  .format(\"console\") \\\n",
        "  .start()"
      ],
      "metadata": {
        "id": "DH6o87iDs2R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query.stop()"
      ],
      "metadata": {
        "id": "ly-MhwodtNns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat <<EOF > /content/emp_data/employee_data2.csv\n",
        "1,John,Sales,3000\n",
        "2,Jane,IT,4000\n",
        "3,Mike,Sales,5000\n",
        "4,Sara,Finance,6000\n",
        "5,David,HR,7000\n",
        "6,Emily,Marketing,6000\n",
        "7,George,HR,4000\n",
        "8,Nina,Sales,5000\n",
        "9,Tom,IT,8000\n",
        "10,Anna,Marketing,3000\n",
        "EOF"
      ],
      "metadata": {
        "id": "fgyuczjyueip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat <<EOF > /content/emp_data/employee_data3.csv\n",
        "11,John,IT,7000\n",
        "12,Jane,HR,4000\n",
        "13,Mike,Finance,5000\n",
        "14,Sara,Sales,6000\n",
        "15,David,Marketing,7000\n",
        "16,Emily,Sales,8000\n",
        "17,George,Finance,3000\n",
        "18,Nina,IT,6000\n",
        "19,Tom,Sales,4000\n",
        "20,Anna,HR,5000\n",
        "EOF"
      ],
      "metadata": {
        "id": "6P5PQA8ovgfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat <<EOF > /content/emp_data/employee_data4.csv\n",
        "21,John,Finance,7000\n",
        "22,Jane,Marketing,6000\n",
        "23,Mike,HR,8000\n",
        "24,Sara,Sales,3000\n",
        "25,David,IT,6000\n",
        "26,Emily,Finance,5000\n",
        "27,George,Marketing,4000\n",
        "28,Nina,HR,7000\n",
        "29,Tom,Finance,5000\n",
        "30,Anna,IT,8000\n",
        "EOF"
      ],
      "metadata": {
        "id": "DKpKHLY3vzim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat /content/emp_data/employee_data4.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsL15NDnwCAl",
        "outputId": "93066870-ef0a-4408-b366-c4861c0b7edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21,John,Finance,7000\n",
            "22,Jane,Marketing,6000\n",
            "23,Mike,HR,8000\n",
            "24,Sara,Sales,3000\n",
            "25,David,IT,6000\n",
            "26,Emily,Finance,5000\n",
            "27,George,Marketing,4000\n",
            "28,Nina,HR,7000\n",
            "29,Tom,Finance,5000\n",
            "30,Anna,IT,8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = transformed_df.writeStream \\\n",
        "  .outputMode(\"append\") \\\n",
        "  .format(\"console\") \\\n",
        "  .start()"
      ],
      "metadata": {
        "id": "3J4Od7JrwIEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlfAOl97_C0x",
        "outputId": "bb6b8298-de35-475b-d85a-cca29c3e578f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.4.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.4.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3xpIHLFBOuS",
        "outputId": "adfb9087-a09b-4f97-9111-d6ba4b27c7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "import uuid\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Output directory in Google Drive\n",
        "output_dir = \"/content/drive/MyDrive/employee_batches\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Infinite loop to keep generating files\n",
        "while True:\n",
        "    # Generate unique filename using current time\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    file_name = f\"employee_data_{timestamp}.csv\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "    # Write 10 employee records to this file\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(\"EmpID,Name,Department,Salary,UniqueID\\n\")  # Header\n",
        "        for _ in range(10):\n",
        "            emp_id = random.randint(1000, 9999)\n",
        "            name = fake.name()\n",
        "            department = fake.job()\n",
        "            salary = random.randint(3000, 12000)\n",
        "\n",
        "\n",
        "            record = f\"{emp_id},{name},{department},{salary}\\n\"\n",
        "            f.write(record)\n",
        "\n",
        "    print(f\"✅ File saved: {file_name}\")\n",
        "\n",
        "    time.sleep(10)  # Wait 30 seconds before generating the next file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "aqYkwpN16e1x",
        "outputId": "2d04f4cc-9ff9-422a-d0f7-c1c16cab2d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File saved: employee_data_20250730_112944.csv\n",
            "✅ File saved: employee_data_20250730_112954.csv\n",
            "✅ File saved: employee_data_20250730_113004.csv\n",
            "✅ File saved: employee_data_20250730_113014.csv\n",
            "✅ File saved: employee_data_20250730_113024.csv\n",
            "✅ File saved: employee_data_20250730_113034.csv\n",
            "✅ File saved: employee_data_20250730_113044.csv\n",
            "✅ File saved: employee_data_20250730_113054.csv\n",
            "✅ File saved: employee_data_20250730_113104.csv\n",
            "✅ File saved: employee_data_20250730_113114.csv\n",
            "✅ File saved: employee_data_20250730_113124.csv\n",
            "✅ File saved: employee_data_20250730_113134.csv\n",
            "✅ File saved: employee_data_20250730_113144.csv\n",
            "✅ File saved: employee_data_20250730_113154.csv\n",
            "✅ File saved: employee_data_20250730_113204.csv\n",
            "✅ File saved: employee_data_20250730_113214.csv\n",
            "✅ File saved: employee_data_20250730_113224.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-104-2377688121.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ File saved: {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait 30 seconds before generating the next file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iFZCLRc_A0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}